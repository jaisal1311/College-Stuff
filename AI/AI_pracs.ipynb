{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_pracs.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMsBw6zijF3pD3FhcPVXtRu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaisal1311/College-Stuff/blob/master/AI/AI_pracs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB6x6EIJ2TLy",
        "colab_type": "text"
      },
      "source": [
        "# Romania Map\n",
        "\n",
        "\n",
        "\n",
        "![ROMANIA MAP](https://miro.medium.com/max/863/1*Lx_LKzRCpXnYaEn-ZdUu1Q.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNbWu-KJryHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "romania_map = {\n",
        "    'Arad': ['Sibiu', 'Timisoara', 'Zerind'],\n",
        "    'Bucharest': ['Fagarus', 'Giurgiu', 'Pitesti', 'Urziceni'],\n",
        "    'Craiova': ['Drobeta', 'Pitesti', 'Rimnicu Vilcea'],\n",
        "    'Drobeta': ['Craiova', 'Mehadia'],\n",
        "    'Eforie': ['Hirsova'],\n",
        "    'Fagarus': ['Bucharest', 'Sibiu'],\n",
        "    'Giurgiu': ['Bucharest'],\n",
        "    'Hirsova': ['Eforie', 'Urziceni'],\n",
        "    'Iasi': ['Neamt', 'Vaslui'],\n",
        "    'Lugoj': ['Mehadia', 'Timisoara'],\n",
        "    'Mehadia': ['Drobeta', 'Lugoj'],\n",
        "    'Neamt': ['Iasi'],\n",
        "    'Oradea': ['Sibiu', 'Zerind'],\n",
        "    'Pitesti': ['Bucharest', 'Craiova', 'Rimnicu Vilcea'],\n",
        "    'Rimnicu Vilcea': ['Craiova', 'Pitesti', 'Sibiu'],\n",
        "    'Sibiu': ['Oradea', 'Arad','Fagarus', 'Rimnicu Vilcea'],\n",
        "    'Timisoara':['Arad', 'Lugoj'],\n",
        "    'Urziceni': ['Bucharest', 'Hirsova', 'Vaslui'],\n",
        "    'Vaslui': ['Iasi', 'Urziceni'],\n",
        "    'Zerind': ['Arad', 'Oradea'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn68kazp8Uvf",
        "colab_type": "text"
      },
      "source": [
        "## BFS traversal until node is found"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK7ho_F0woiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "95811190-565b-456c-e928-52a578abea11"
      },
      "source": [
        "def BFS_traversal(G, s, d):\n",
        "    if s == d:\n",
        "        return 'Masti Nai...ðŸ˜…'\n",
        "    visited = [s]\n",
        "    q = [s]\n",
        "    while q:\n",
        "        u = q.pop(0)\n",
        "        for v in G[u]:\n",
        "            if v not in visited:\n",
        "                if v == d:\n",
        "                    visited.append(v)\n",
        "                    return ' => '.join(visited)\n",
        "                else:\n",
        "                    q.append(v)\n",
        "                    visited.append(v)\n",
        "    return 'Not Found..ðŸ˜ž'\n",
        "\n",
        "BFS_traversal(romania_map, 'Arad', 'Arad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Masti Nai...ðŸ˜…'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L9HODYV8aYI",
        "colab_type": "text"
      },
      "source": [
        "## BFS Shortest Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cjYO89D0_nW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9d323ed1-daba-4d03-8787-56b7b2114022"
      },
      "source": [
        "def BFS_shortest_path(G, source, destination):\n",
        "    visited= []\n",
        "    queue = [[source]]\n",
        "\n",
        "    if source == destination:\n",
        "        return 'No masti..ðŸ˜…'\n",
        "    \n",
        "    while queue:\n",
        "        path = queue.pop(0)\n",
        "        node = path[-1]\n",
        "\n",
        "        if node not in visited:\n",
        "            neighbours = G[node]\n",
        "        \n",
        "        for neighbour in neighbours:\n",
        "            new_path = list(path)\n",
        "            new_path.append(neighbour)\n",
        "            queue.append(new_path)\n",
        "\n",
        "            if neighbour == destination:\n",
        "                return (' => '.join(new_path), 'âœ¨')\n",
        "        visited.append(node)\n",
        "    return 'Not Found..ðŸ˜ž'\n",
        "BFS_shortest_path(romania_map, 'Arad', 'Arad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'No masti..ðŸ˜…'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q30lj6bJsL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "0d533161-8a84-4768-c575-67cbb77598ed"
      },
      "source": [
        "def DFS(graph, start):\n",
        "    visited, stack = set(), [start]\n",
        "    while stack:\n",
        "        vertex = stack.pop()\n",
        "        if vertex not in visited:\n",
        "            visited.add(vertex)\n",
        "            stack.extend(graph[vertex])\n",
        "    return visited\n",
        "\n",
        "DFS(romania_map, 'Craiova')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Arad',\n",
              " 'Bucharest',\n",
              " 'Craiova',\n",
              " 'Drobeta',\n",
              " 'Eforie',\n",
              " 'Fagarus',\n",
              " 'Giurgiu',\n",
              " 'Hirsova',\n",
              " 'Iasi',\n",
              " 'Lugoj',\n",
              " 'Mehadia',\n",
              " 'Neamt',\n",
              " 'Oradea',\n",
              " 'Pitesti',\n",
              " 'Rimnicu Vilcea',\n",
              " 'Sibiu',\n",
              " 'Timisoara',\n",
              " 'Urziceni',\n",
              " 'Vaslui',\n",
              " 'Zerind'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTsl8SRSnIUk",
        "colab_type": "text"
      },
      "source": [
        "## IRIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-2LMelZ_dAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "82b914e7-8412-4f2f-a63b-631311c6992e"
      },
      "source": [
        "iris = pd.read_csv('/content/iris_csv.csv')\n",
        "iris.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepallength</th>\n",
              "      <th>sepalwidth</th>\n",
              "      <th>petallength</th>\n",
              "      <th>petalwidth</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepallength  sepalwidth  petallength  petalwidth        class\n",
              "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
              "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
              "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
              "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
              "4          5.0         3.6          1.4         0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEvRCybnicG0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "01882901-61b5-4b9e-a8c8-798e6fbbb555"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X, y = load_iris(return_X_y=True)\n",
        "clf = LogisticRegression(random_state=0).fit(X, y)\n",
        "clf.predict(X[:2, :])\n",
        "clf.predict_proba(X[:2, :])\n",
        "clf.score(X, y)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9733333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vNIxHfHignp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e2fcaf3-ff98-40c1-f2bd-c6d384d73198"
      },
      "source": [
        "clf.predict(X)[0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7LvV6gLnB7V",
        "colab_type": "text"
      },
      "source": [
        "## Diabetes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eSQV94BjV1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "ca47e295-b2c6-4a79-cb3c-550895b5b148"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "data = pd.read_csv('/content/diabetes.csv')\n",
        "data"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  ...  Age  Outcome\n",
              "0              6      148  ...   50        1\n",
              "1              1       85  ...   31        0\n",
              "2              8      183  ...   32        1\n",
              "3              1       89  ...   21        0\n",
              "4              0      137  ...   33        1\n",
              "..           ...      ...  ...  ...      ...\n",
              "763           10      101  ...   63        0\n",
              "764            2      122  ...   27        0\n",
              "765            5      121  ...   30        0\n",
              "766            1      126  ...   47        1\n",
              "767            1       93  ...   23        0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41G7IOSDm-oI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0184cf21-a227-4b35-89fe-ec679e5550ce"
      },
      "source": [
        "inputs = torch.from_numpy(np.array(data.iloc[:, :-1])).float()\n",
        "outputs = torch.from_numpy(np.array(data.iloc[:, -1])).float()\n",
        "outputs.unique()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg4MJ0f3nZkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(8, 16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16, 32),\n",
        "    torch.nn.Tanh(),\n",
        "    torch.nn.Linear(32, 16),\n",
        "    torch.nn.LeakyReLU(),\n",
        "    torch.nn.Linear(16, 8),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Linear(8, 1),\n",
        "    torch.nn.Sigmoid(),\n",
        ")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8957z3Xna0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = F.binary_cross_entropy\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.00005)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4019cn2nfQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "622c46f7-7a76-475f-b7d2-78c30eb0a46c"
      },
      "source": [
        "model.train()\n",
        "for t in range(1000):\n",
        "\n",
        "    Y_pred = model(inputs)\n",
        "\n",
        "    loss = loss_fn(Y_pred, outputs)\n",
        "    \n",
        "    if t % 100 == 0:\n",
        "        print(\"Epoch:\", t, \"\\tLoss:\", loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Using a target size (torch.Size([768])) that is different to the input size (torch.Size([768, 1])) is deprecated. Please ensure they have the same size.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tLoss: 0.7531358599662781\n",
            "Epoch: 100 \tLoss: 0.7523606419563293\n",
            "Epoch: 200 \tLoss: 0.7515912055969238\n",
            "Epoch: 300 \tLoss: 0.7508273124694824\n",
            "Epoch: 400 \tLoss: 0.7500689029693604\n",
            "Epoch: 500 \tLoss: 0.7493161559104919\n",
            "Epoch: 600 \tLoss: 0.7485687136650085\n",
            "Epoch: 700 \tLoss: 0.7478268146514893\n",
            "Epoch: 800 \tLoss: 0.7470903396606445\n",
            "Epoch: 900 \tLoss: 0.7463590502738953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEciDZpfnjjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0e79140c-559a-4278-949c-dd0af085996b"
      },
      "source": [
        "print(torch.round(model(inputs[99])))\n",
        "print(outputs[99])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.], grad_fn=<RoundBackward>)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_aldpCvnmR6",
        "colab_type": "text"
      },
      "source": [
        "## Logical Units NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsZCx7sXnlhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}